{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ранее](/courses/recommendation-systems/factorization-machines-pytorch) мы разобрали алгоритм факторизационных машин, а именно, поняли, чем как переформулировать задачу заполнения пропусков в матрице в задачу регрессии, как при помощи регресии моделировать взаимодействие признаков и почему это едва ли возможно сделать в задаче рекоммендации обычным при помощи попарного произведения всех возможных признаков. Факторизационные машины решают проблему сложности моделирования взаимодействия между всеми парами признаков, используя некоторого рода уловку — они ставят в соответствие к каждому признаку вектор низкой размерности, координаты которого свидетельствуют о близости признаков между собой. Благодаря этому, а также формуле, выведенной автором из определения факторизационных машин, нам не нужно подбирать веса для всех возможных пар признаков, а достаточно определить координаты этих векторов, что делается за линейное время.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from fastFM.datasets import make_user_item_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y, _ = make_user_item_regression(n_user=100, n_item=50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "class FieldAwareFactorizationMachine(nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim):\n",
    "        super().__init__()\n",
    "        self.num_fields = len(field_dims)\n",
    "        self.embeddings = torch.nn.ModuleList([\n",
    "            torch.nn.Embedding(sum(field_dims), embed_dim) for _ in range(self.num_fields)\n",
    "        ])\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
    "        for embedding in self.embeddings:\n",
    "            torch.nn.init.xavier_uniform_(embedding.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        xs = [self.embeddings[i](x) for i in range(self.num_fields)]\n",
    "        ix = list()\n",
    "        for i in range(self.num_fields - 1):\n",
    "            for j in range(i + 1, self.num_fields):\n",
    "                ix.append(xs[j][:, i] * xs[i][:, j])\n",
    "        ix = torch.stack(ix, dim=1)\n",
    "        return ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 150)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_by_field = {\n",
    "    \"users\": list(range(100)),\n",
    "    \"items\": list(range(100, 150))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFM(nn.Module):\n",
    "    def __init__(self, fields: dict, embed_dim=3):\n",
    "        super().__init__()\n",
    "        self.fields = fields\n",
    "        self.embeddings = torch.nn.ModuleList([\n",
    "            torch.nn.Embedding(sum(field_dim), embed_dim) for field_name, field_dim in self.fields.items()\n",
    "        ])\n",
    "        for embedding in self.embeddings:\n",
    "            torch.nn.init.xavier_uniform_(embedding.weight.data)\n",
    "#         self.V = nn.Parameter(torch.randn(features_num, k), requires_grad=True)\n",
    "        torch.nn.init.xavier_uniform_(self.V.data)\n",
    "        self.linear = nn.Linear(features_num, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out_1 = ((X @ self.V) ** 2).sum(1, keepdim=True)\n",
    "        out_2 = ((X ** 2) @ (self.V ** 2)).sum(1, keepdim=True)\n",
    "\n",
    "        out_interaction = (out_1 - out_2) / 2\n",
    "        out_linear = self.linear(X)\n",
    "        return out_interaction + out_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788741139133923"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "X_train_tensor, y_train_tensor = torch.from_numpy(X_train.toarray()), torch.from_numpy(y_train.reshape(-1, 1))\n",
    "\n",
    "model = FM(X_train.shape[1])\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor.float())\n",
    "    loss = criterion(predictions, y_train_tensor.float())\n",
    "    # get gradients\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "X_test_tensor = torch.from_numpy(X_test.toarray())\n",
    "predictions = model(X_test_tensor.float())\n",
    "r2_score(y_test, predictions.squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ailab.criteo.com/ctr-prediction-linear-model-field-aware-factorization-machines/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
