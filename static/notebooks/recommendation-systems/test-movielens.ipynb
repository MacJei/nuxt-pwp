{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from loguru import logger\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "import os\n",
    "import copy\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.add(\"/tmp/test-movielens.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load train data\n",
    "# train_df = pd.read_csv('../../../../tmp/dota_train_binary_heroes.csv.zip', index_col='match_id_hash')\n",
    "# test_df = pd.read_csv('../../../../tmp/dota_train_binary_heroes.csv.zip', index_col='match_id_hash')\n",
    "# target = pd.read_csv('../../../../tmp/train_targets.csv.zip', index_col='match_id_hash')\n",
    "# y = target['radiant_win'].values.astype(np.float32)\n",
    "# y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 10334)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv(\"../../datasets/movielens-small/ratings.csv\")\n",
    "ratings_onehot = pd.get_dummies(df_ratings[[\"userId\", \"movieId\"]].astype(\"category\"))\n",
    "ratings_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ratings_onehot.sample(frac=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = ratings_onehot[~ratings_onehot.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[\"rating_bin\"] = (df_ratings.rating <= 3).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ratings[df_ratings.index.isin(train_df.index)][\"rating_bin\"].values.astype(np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.values.astype(np.float32)\n",
    "X_test = test_df.values.astype(np.float32)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "train_preds = np.zeros(y.shape)\n",
    "test_preds = np.zeros((X_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epochs = 300\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "opt_params = {'lr': 0.01, 'momentum': 0.9}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X = X_train\n",
    "folds = KFold(n_splits=5, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor, X_test, y_tensor = torch.from_numpy(X).to(device), torch.from_numpy(X_test).to(device), torch.from_numpy(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-16 20:15:35.211 | DEBUG    | __main__:<module>:3 - fold 1\n",
      "2020-03-16 20:19:32.234 | DEBUG    | __main__:<module>:52 - epoch 30 train loss: 0.709 valid loss 0.712 valid roc auc 0.503\n",
      "2020-03-16 20:23:26.199 | DEBUG    | __main__:<module>:52 - epoch 60 train loss: 0.700 valid loss 0.702 valid roc auc 0.503\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-42423eddb488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mvalid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mepoch_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_fold, (train_ind, valid_ind) in enumerate(folds.split(X, y)):\n",
    "\n",
    "    logger.debug(f'fold {n_fold+1}')\n",
    "\n",
    "    train_set = TensorDataset(X_tensor[train_ind], y_tensor[train_ind])\n",
    "    valid_set = TensorDataset(X_tensor[valid_ind], y_tensor[valid_ind])\n",
    "\n",
    "    loaders = {'train': DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "               'valid': DataLoader(valid_set, batch_size=batch_size, shuffle=False)}\n",
    "\n",
    "    model = TorchFM(n=X_train.shape[1], k=5)\n",
    "    model.to(device)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), **opt_params)\n",
    "\n",
    "    best_score = 0.\n",
    "    for epoch in range(epochs):\n",
    "        losses = {'train': 0., 'valid': 0}\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            for batch_x, batch_y in loaders[phase]:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch_x)\n",
    "                loss = criterion(out, batch_y)\n",
    "                losses[phase] += loss.item()*batch_x.size(0)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "#                             scheduler.step()\n",
    "                        optimizer.step()\n",
    "\n",
    "            losses[phase] /= len(loaders[phase].dataset)\n",
    "\n",
    "        # after each epoch check if we improved roc auc and if yes - save model\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            valid_preds = (model(X_tensor[valid_ind]).cpu().numpy())\n",
    "            epoch_score = roc_auc_score(y[valid_ind], valid_preds)\n",
    "            if epoch_score > best_score:\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_score = epoch_score\n",
    "\n",
    "        if ((epoch+1) % 30) == 0:\n",
    "            logger.debug(f'epoch {epoch+1} train loss: {losses[\"train\"]:.3f} valid loss {losses[\"valid\"]:.3f} valid roc auc {epoch_score:.3f}')\n",
    "\n",
    "    # prediction on valid set\n",
    "    with torch.no_grad():\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        model.eval()\n",
    "\n",
    "        train_preds[valid_ind] = (model(X_tensor[valid_ind]).cpu().numpy())\n",
    "        fold_score = roc_auc_score(y[valid_ind], train_preds[valid_ind])\n",
    "        scores.append(fold_score)\n",
    "        logger.debug(f'Best ROC AUC score {fold_score}')\n",
    "        models.append(model)\n",
    "\n",
    "        test_preds += (model(X_test).cpu().numpy())\n",
    "\n",
    "logger.debug('CV AUC ROC', np.mean(scores), np.std(scores))\n",
    "\n",
    "test_preds /= folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastFM.datasets import make_user_item_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This sets up a small test dataset.\n",
    "X, y, _ = make_user_item_regression(label_stdev=.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastFM import als\n",
    "fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=2, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "y_pred = fm.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945042051187586"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 40)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, features_num=None, k=5):\n",
    "        super().__init__()\n",
    "        self.V = nn.Parameter(torch.randn(features_num, k), requires_grad=True)\n",
    "        self.linear = nn.Linear(features_num, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out_1 = ((X @ self.V) ** 2).sum(1, keepdim=True)\n",
    "        out_2 = ((X ** 2) @ (self.V ** 2)).sum(1, keepdim=True)\n",
    "\n",
    "        out_interaction = 0.5 * (out_1 - out_2)\n",
    "        out_linear = self.linear(X)\n",
    "        return out_interaction + out_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor, y_tensor = torch.from_numpy(X_train), torch.from_numpy(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FM(X_train.shape[1])\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_tensor.float())\n",
    "    loss = criterion(predictions, y_tensor.float())\n",
    "    # get gradients\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842598586896495"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, predictions.squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
