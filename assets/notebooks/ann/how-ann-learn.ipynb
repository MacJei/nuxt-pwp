{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Минимизация функций стоимости методом градиентного спуска (gradient descent)\n",
    "\n",
    "Однако, если в случае с одним перцептроном всё действительно очень просто, то что делать, когда целевая функция явно не задана, а является сложной композицией других функций, как это и происходит в случае нейронных сетей? Мы не может просто продифференцировать эту композицию целиком, т.к. она не является выпуклой, как, например квадратичная функция. Напротив, у неё есть более одного локального минимума, а графически она похожа на волну.\n",
    "\n",
    "![](img/сonvex-vs-nonconvex-functions.png)\n",
    "\n",
    "Таким образом мы относительно легко можем найти локальный миниум, но не можем быть уверены является ли он ещё и глобальным.\n",
    "![](img/local-global-extremum.png)\n",
    "\n",
    "<details>\n",
    "  <summary><span>Число же таких локальных минимумов может исчисляться миллионами, поэтому пересчитать все нет никакой возможности.</span></summary>\n",
    "    Объяснение количества локальных минимумов от Сергея Николенко:\n",
    "<blockquote class=\"blockquote\">\n",
    "      <p>Заметим еще, что разных экстремумов может быть очень, очень много. Их легко может оказаться экспоненциально много от числа нейронов (то есть от числа аргументов функции, которую мы оптимизируем), и перечислить их все тоже нет совершенно никакой возможности. В нейронной сети этот эффект, кстати, очень легко продемонстрировать: представьте себе, что мы взяли нейроны одного из внутренних слоев многослойной сети и поменяли их все местами, то есть заменили веса, ведущие в один нейрон и из него, на соответствующие веса другого нейрона. Совершенно очевидно, что в нейронной сети стандартной архитектуры от этого ровным счетом ничего не изменится: на следующий уровень придут ровно те же активации, что и раньше, ведь мы поменяли входные и выходные веса согласованным образом.</p>\n",
    "<p>А это значит, что если у функции ошибки нейронной сети есть какой-то локальный максимум, то другой локальный максимум легко получить, просто переставив веса нейронов на внутреннем слое. Сколько таких перестановок? Правильно, $n!$, где $n$ — число нейронов, которые мы переставляем; вот вам и экспоненциальное число локальных максимумов. Конечно, данный конкретный пример не очень содержателен: нам все равно, какой из эквивалентных максимумов выбрать; но существенно разных максимумов тоже может быть очень много.</p>\n",
    "    \n",
    "<footer class=\"blockquote-footer\">Сергей Николенко. <cite title=\"Глубокое обучение. Погружение в мир нейронных сетей\">Глубокое обучение. Погружение в мир нейронных сетей, стр. 70-71 (https://www.zotero.org/ihun/items/itemKey/V46ZQDGH)</cite>.</footer>\n",
    "</blockquote>\n",
    "</details>\n",
    "\n",
    "Более того, из-за возможности оверфиттинга мы даже не можем быть уверены, что действительно хотим оказаться в этом глобальном экстремуме.\n",
    "\n",
    "И тут, как вы уже, наверное, догадались, на помощь приходит градиентный спуск — эвристический метод нахождения минимального значения функции потерь.\n",
    "<div class=\"note\">Метод называет <a href=\"https://en.wikipedia.org/wiki/Heuristic_(computer_science)\" target=\"_blank\">эвристическим</a> (от греческого εὑρίσκω «я нахожу, открываю»), если он предназначен для более быстрого решения проблемы в случае, когда классические методы слишком медленные, или для поиска приближенного решения, когда классические методы не могут найти какое-либо точное решение.</div>\n",
    "\n",
    "Самое важное здесь разобраться с тем, что из себя представляет градиент — это вектор вида Если $\\varphi$ — функция $n$ переменных $x_{1},\\ldots, x_{n}$, то её градиентом называется $n$-мерный вектор\n",
    "\n",
    "$$\\left(\\frac  {\\partial \\varphi }{\\partial x_{1}},\\ldots ,\\frac{\\partial \\varphi }{\\partial x_{n}}\\right),$$\n",
    "компоненты которого равны частным производным $\\varphi$  по всем её аргументам. \n",
    "\n",
    "<details>\n",
    "<summary><span>Для тех, кто забыл, что такое частная произоводная я прилагаю небольшой пример вычисления градиента.</span></summary>\n",
    "\n",
    "**Дано**: функция $u = x^2 + 2xy + y^2 + z^2$. Найдите градиент этой функции в точке $A$ с координатами $(1;1;1)$.\n",
    "\n",
    "**Решение**. Первым делом найдём частную производную по каждой переменной:\n",
    "    \n",
    "* $\\frac{\\partial u}{\\partial x}=2x+2y$;\n",
    "* $\\frac{\\partial u}{\\partial y}=2x+2y$;\n",
    "* $\\frac{\\partial u}{\\partial z}=2z$.\n",
    "    \n",
    "По определению градиента получаем следующий вектор градиента:\n",
    "$$\\nabla u = (2x+2y)\\bar{i} + (2x+2y)\\bar{j} +2z\\bar{k},$$\n",
    "где $i$, $j$ и $k$ — это [базисные вектора](https://en.wikipedia.org/wiki/Basis_(linear_algebra)). Этот вектор также можно записать как $(2x+2y; 2x+2y; 2z)$.\n",
    "\n",
    "Для определения значения градиента функции $u$ в точке $A$ подставляем координаты в полученную функцию:\n",
    "    \n",
    "$$\\nabla u_A = (2\\cdot 1+2\\cdot 1)\\bar{i} + (2\\cdot 1+2\\cdot 1)\\bar{j} +2\\cdot 1z\\bar{k} = \\\\ =4\\bar{i}+4\\bar{j}+2\\bar{k}.$$\n",
    "    \n",
    "Готово, вы прекрасны!\n",
    "</details>\n",
    "\n",
    "Теперь поговорим о том, куда спускается градиент. Одним из свойств градиента является то, что он указывает направление, в котором некоторая функция возрастает больше всего (антиградиент, соответственно, указывает направление наискорейшего убывания функции), это довольно [интуитивный вывод](https://math.stackexchange.com/questions/221968/why-must-the-gradient-vector-always-be-directed-in-an-increasing-direction). Проще всего это понять, если представить шарик, который катится по неровной поверхности с некоторой скоростью. Шарик будет стремиться закатиться в ложбинки на этой повернхности, но если их глубина будет недостаточна, а скорость шарика высока, он может выкатиться и направиться к следующей, более глубокой впадине, пока, наконец не закатится в глубокую ямку, где и остановится.\n",
    "\n",
    "<img src=\"img/gradient-descent.gif\" title=\"https://medium.com/@arvind_70185/gradient-descent-for-machine-learning-52ce08c96296\">\n",
    "\n",
    "В нашем случае поверхность будет задаваться $j+1$ координатами, где $j$ — количество переменных, а её одно изменрение — глубину — представляет собой величину ошибки в каждой конкретной точке. Например, на картинке выше изображена трехмерная поверхность функции от двух переменных.\n",
    "\n",
    "Дальше всё просто (https://www.zotero.org/ihun/items/itemKey/BTZUC656). Зная направление уменьшения функции, мы можем подбирать веса переменных таким образом, чтобы двигаться в этом направлении. Итак, у нас есть веса переменных (коэффициенты, параметры) $\\theta_1, \\theta_2\\dots,\\theta_n$ и фукнция ошибок $E(\\Theta)$. Для изменения веса $j$-ого признака в нужную сторону на шаге $t$ мы вычитаем из его веса частную производную функции ошибок по этому параметру на шаге $t-1$:\n",
    "\n",
    "$$\\theta_j^t=\\theta_j^{t-1}-\\alpha\\frac{\\partial E(\\Theta)}{\\partial \\theta_j^{t-1}}$$.\n",
    "\n",
    "Получается, что при градиентном спуске больше всего изменяется тот параметр, который имеет самую большую по модулю производную. В этой формуле $\\alpha$ — это его скорость обучения, она регулирует размер шага, который мы делаем в направлении градиента.\n",
    "\n",
    "Есть несколько разновидностей градиентного спуска (https://www.zotero.org/ihun/items/itemKey/Y5Q7CZK2). Тот, который мы разобрали, называется пакетным (batch), потому что для одного шага градиентного спуска, нужно вычислить функцию ошибок по всему \"пакету\" — тренировочному множеству. Это часто крайне затратно, поэтому чаще используется стохастический (т.е. случайный) градиентный спуск. Его отличие в том, что веса подправляются не после прохода по всему тренировочному множеству, а после каждого примера. У этого подхода два преимущества:\n",
    "1. Ошибка на каждом шаге считается быстро, веса меняются сразу же, что очень сильно ускоряет обучение. Обучение может сойтись ещё до того, как мы даже один раз пробежались по всем тренировочным примерам. К тому же не надо хранить всю обучающую выборку в памяти.\n",
    "2. Стохастический градиентный спуск работает «более случайно», чем обычный, и поэтому можно надеяться, что он не остановится в маленьких локальных минимумах. Пакетный же спуск хорош для строго выпуклых функций, потому что уверенно стремится к минимуму глобальному или локальному.\n",
    "3. Подходит для онлайн-обучения, т.е. в случаях, когда обучающая выборка постоянно обновляется.\n",
    "\n",
    "Однако и тут есть недостатки — обновлять веса модели после каждого тренировочного примера может быть накладно, поэтому можно скрестить два этих варианта, получив мини-пакетный (mini-batch) спуск, который за раз обрабатывает, к примеру, 100 элементов, а не все или один. За счёт возможности распрараллерирования это всё равно быстрее, чем в случае с пакетным спуском, а результат даёт даже лучше (https://www.zotero.org/ihun/items/itemKey/7WKXHG2T).\n",
    "\n",
    "![](img/stochastic-vs-minibatch.png)\n",
    "\n",
    "<details>\n",
    "<summary><span>Ну и наполследок видео по теме с канала Гранта Сандерсона.</span></summary>\n",
    "<div class=\"embed-responsive embed-responsive-16by9\">\n",
    "  <iframe class=\"embed-responsive-item\" height=\"auto\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe>\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод обратного распространения ошибки (backpropagation)\n",
    "\n",
    "Итак, для поиска направления уменьшения ошибок функции и обновления весов используется метод градиентного спуска. Алгоритмически градиентный спуск реализуется через обратное распространение ошибки: мы постепенно считаем градиент сложной композиции элементарных функций и передаем эти градиенты по сети в обратном направлении. Хорошее объяснение метода обратного распространения ошибки от Andrej Karpathy есть в чётвертой лекции курса CS231n Convolutional Neural Networks for Visual Recognition (https://www.zotero.org/ihun/items/itemKey/CPRABN99), и важно понимать(https://www.zotero.org/ihun/items/itemKey/B6ZGGLPS) его.\n",
    "\n",
    "Прямое распространение можно рассматривать как длинный ряд вложенных уравнений, решая которые мы расчитываем ошибку при текущих параметрах:\n",
    "$$f(x) = A(B(C(x))),$$\n",
    "где $A$, $B$, и $C$ — функции активации на различных слоях.\n",
    "\n",
    "Обратное распространение — это просто приложение правила цепочки (дифференцирования сложной функции) для поиска производных потерь по любой переменной во вложенном уравнении (https://www.zotero.org/ihun/items/itemKey/5HSQX532). Пользуясь правилом цепочки, мы легко вычисляем производную $f(x)$ по $x$:\n",
    "$$f′(x)=f′(A)⋅A′(B)⋅B′(C)⋅C′(x).$$\n",
    "\n",
    "Чтобы найти производную по $B$, вы можете сделать вид, что $B(C(x))$ является константой, заменить ее переменной-заполнителем $B$, и продолжить поиск производной по $B$ стандартно:\n",
    "$$f′(B)=f′(A)⋅A′(B).$$\n",
    "Аналогично находятся прозиводные и по другим переменным.\n",
    "\n",
    "Этот простой метод распространяется на любую переменную внутри функции, и позволяет нам в точности определить влияние каждой переменной на общий результат. Наиболее интуитивно понятная иллюстрация (https://www.zotero.org/ihun/items/itemKey/T59I9IHZ) работы метода приведена ниже\n",
    "\n",
    "<div class=\"embed-responsive embed-responsive-1by1\">\n",
    "  <iframe class=\"embed-responsive-item\" height=\"auto\" src=\"https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe>\n",
    "</div>\n",
    "\n",
    "[Источник](https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/).\n",
    "\n",
    "<details>\n",
    "<summary><span>В конце, как обычно, видео с канала 3Blue1Brown.</span></summary>\n",
    "<div class=\"embed-responsive embed-responsive-16by9\">\n",
    "  <iframe class=\"embed-responsive-item\" height=\"auto\" src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe>\n",
    "</div>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
